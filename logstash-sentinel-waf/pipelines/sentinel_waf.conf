input {
  beats {
    host => "${LOGSTASH_BEATS_HOST:0.0.0.0}"
    port => "${LOGSTASH_BEATS_PORT:5044}"
    client_inactivity_timeout => "${LOGSTASH_BEATS_TIMEOUT:60}"
  }
}

filter {
  # Create clones for Sentinel and SQS outputs.
  clone {
    clones => ['waf_to_sentinel', 'logstash_to_sqs' ]
  }

  # Filter the message being sent to Sentinel and remove message field
  if ([type] == 'waf_to_sentinel') {
    json {
      source => "message"
    }

    # Convert raw timestamp from Epoch format to UTC for ingestion into Sentinel
    date {
      match => [ "timestamp","UNIX_MS" ]
      target => "timestamp"
      timezone => "UTC"
    }

    # Remove the following fields as not needed
    mutate {
      remove_field => ["message","@timestamp","agent","ecs","input","log","tags"]
    }
  }
}

output {

  # Standard out for debugging to console
  # stdout {}

  if [type] == 'waf_to_sentinel' {
    # Sentinel Output
    microsoft-sentinel-log-analytics-logstash-output-plugin {
      client_app_Id => "${SENTINEL_CLIENT_APP_ID}"
      client_app_secret => "${SENTINEL_CLIENT_APP_SECRET}"
      tenant_id => "${SENTINEL_TENANT_ID}"
      data_collection_endpoint => "${SENTINEL_DATA_COLLECTION_ENDPOINT}"
      dcr_immutable_id => "${SENTINEL_DCR_IMMUTABLE_ID}"
      dcr_stream_name => "${SENTINEL_DCR_STREAM_NAME}"
      create_sample_file=> false
    }
  }

  if [type] == 'logstash_to_sqs' {
    # SQS output for S3 bucket pruning
    sqs {
      queue => "${SQS_OUTPUT_QUEUE}"
      region => "${region}"
    }
  }

}